<<<<<<< HEAD
use charset::Charset;

=======
>>>>>>> 35197c4184657bf595ccb3cdfd6a66107eaf1b5b
use crate::lexer::{EncodedWordTokens, Token};

use core::slice::SlicePattern;
use std::convert::TryFrom;

pub type Result<T> = std::result::Result<T, Error>;

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum Encoding {
    B,
    Q,
}

impl Encoding {
    pub const B_CHAR: char = 'b';
    pub const Q_CHAR: char = 'q';
    pub const ENCODING_LENGTH: usize = 1;
}

impl TryFrom<Token> for Encoding {
    type Error = Error;

    fn try_from(token: Token) -> Result<Self> {
        if token.len() > Self::ENCODING_LENGTH {
            return Err(Error::EncodedWordTooBig);
        }

        let encoding = token.first().ok_or(Error::EmptyEncoding)?;
        let encoding = *encoding as char;
        let encoding = encoding.to_ascii_lowercase();

        match encoding {
            Encoding::Q_CHAR => Ok(Self::Q),
            Encoding::B_CHAR => Ok(Self::B),
            _ => Err(Error::UnknownEncoding(encoding)),
        }
    }
}

#[derive(Debug, Clone)]
pub struct EncodedWordParsed {
    pub charset: Charset,
    pub encoding: Encoding,
    pub encoded_text: crate::lexer::EncodedText,
}

impl TryFrom<EncodedWordTokens> for EncodedWordParsed {
    type Error = Error;

    fn try_from(encoded_word_tokens: EncodedWordTokens) -> Result<Self> {
        let charset = Charset::for_label(&encoded_word_tokens.charset)
            .ok_or_else(|| Error::UnknownCharset(format!("{:?}", encoded_word_tokens.charset)))?;
        let encoding = Encoding::try_from(encoded_word_tokens.encoding)?;

        Ok(EncodedWordParsed {
            charset,
            encoding,
            encoded_text: encoded_word_tokens.encoded_text,
        })
    }
}

#[derive(thiserror::Error, Debug, Clone)]
pub enum Error {
    #[error("Unknown charset: {}", .0)]
    UnknownCharset(String),

    #[error("Unknown encoding: {}. Encoding can be only either 'Q' or 'B'.", .0)]
    UnknownEncoding(char),

    #[error("The encoded word is too big")]
    EncodedWordTooBig,

    #[error("Encoding is empty")]
    EmptyEncoding,
}

<<<<<<< HEAD
pub fn run(encoded_word: EncodedWordTokens) -> Result<EncodedWordParsed> {
    EncodedWordParsed::try_from(encoded_word)
=======
fn first_char_of(vec: &[u8]) -> Result<char> {
    match std::str::from_utf8(vec)?.to_uppercase().chars().next() {
        Some(c) => Ok(c),
        None => Ok('Q'),
    }
}

pub fn run(encoded_word: EncodedWordTokens) -> Result<Ast> {
    let mut curr_charset: Token = encoded_word.charset;
    let mut curr_encoding: char = first_char_of(encoded_word.encoding.as_slice());
    let mut ast: Ast = vec![];

    const CR: u8 = '\r' as u8;
    const LF: u8 = '\n' as u8;
    const SPACE: u8 = ' ' as u8;

    for token in tokens {
        use crate::lexer::Token::*;

        match token {
            Charset(charset) => {
                curr_charset = &charset;
            }
            Encoding(encoding) => {
                curr_encoding = first_char_of(&encoding)?;
            }
            EncodedText(encoded_bytes) => {
                ast.push(Node::EncodedBytes(EncodedBytes {
                    charset: curr_charset.clone(),
                    encoding: curr_encoding,
                    bytes: encoded_bytes.clone(),
                }));
            }
            ClearText(decoded_bytes) => match decoded_bytes[..] {
                [CR, LF, SPACE] => (),
                [LF, SPACE] => (),
                [SPACE] => (),
                _ => ast.push(Node::ClearBytes(decoded_bytes.clone())),
            },
        }
    }

    Ok(ast)
>>>>>>> 35197c4184657bf595ccb3cdfd6a66107eaf1b5b
}

#[cfg(test)]
mod tests {

    use crate::parser;
    use crate::lexer;
    use crate::parser::Encoding;

    /// Example taken from:
    /// https://datatracker.ietf.org/doc/html/rfc2047#section-8
    ///
    /// `From` field
    #[test]
    fn test_parse1() {
        let message = "=?US-ASCII?Q?Keith_Moore?=".as_bytes();
        let tokens = lexer::run(&message).unwrap();
        let parsed = parser::run(tokens).unwrap();

        assert_eq!(parsed.encoding, Encoding::Q);
        assert_eq!(parsed.encoded_text, "Keith_Moore".as_bytes(), "{:#?}", parsed.encoded_text);
    }

    /// Example taken from:
    /// https://datatracker.ietf.org/doc/html/rfc2047#section-8
    ///
    /// `To` field
    #[test]
    fn test_parse2() {
        let message = "=?ISO-8859-1?Q?Keld_J=F8rn_Simonsen?=".as_bytes();
        let tokens = lexer::run(&message).unwrap();
        let parsed = parser::run(tokens).unwrap();

        assert_eq!(parsed.encoding, Encoding::Q);
        assert_eq!(parsed.encoded_text, "Keld_J=F8rn_Simonsen".as_bytes());
    }

    /// Example taken from:
    /// https://datatracker.ietf.org/doc/html/rfc2047#section-8
    ///
    /// `CC` field
    #[test]
    fn test_parse3() {
        let message = "=?ISO-8859-1?Q?Andr=E9?=".as_bytes();
        let tokens = lexer::run(&message).unwrap();
        let parsed = parser::run(tokens).unwrap();

        assert_eq!(parsed.encoding, Encoding::Q);
        assert_eq!(parsed.encoded_text, "Andr=E9".as_bytes());
    }

    /// Example taken from:
    /// https://datatracker.ietf.org/doc/html/rfc2047#section-8
    ///
    /// `Subject` field
    #[test]
    fn test_parse4() {
        let message = "=?ISO-8859-1?B?SWYgeW91IGNhbiByZWFkIHRoaXMgeW8=?=".as_bytes();
        let tokens = lexer::run(&message).unwrap();
        let parsed = parser::run(tokens).unwrap();

        assert_eq!(parsed.encoding, Encoding::B);
        assert_eq!(parsed.encoded_text, "SWYgeW91IGNhbiByZWFkIHRoaXMgeW8=".as_bytes());
    }
}
